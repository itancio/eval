LLM Evaluation Platform

For this project, I was tasked with building an evaluation platform where you test to see what combination of system prompts and LLMs work best for your startup's use case.

I used Groq and Gemini for the LLMs.

Project Requirements:

- Create a full stack web app with an interface for inputting prompts and viewing responses from multiple LLMs side-by-side
- Integrate metrics such as accuracy, relevancy, and response time for each LLM
- Store user prompts and experiment results in a database
- Implement an analytics dashboard for visualizing performance metrics for different prompts and LLMs

- See here: https://llm-eval.netlify.app
